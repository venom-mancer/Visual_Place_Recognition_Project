{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Adaptive Re-ranking Pipeline - Google Colab Execution\n",
        "\n",
        "This notebook runs the complete adaptive re-ranking pipeline in Google Colab.\n",
        "\n",
        "## Pipeline Overview:\n",
        "1. Setup environment and install dependencies\n",
        "2. Download datasets\n",
        "3. Run VPR evaluation\n",
        "4. Extract features (8 improved features)\n",
        "5. Train logistic regression model\n",
        "6. Apply model with threshold calibration\n",
        "7. Run adaptive image matching (only hard queries)\n",
        "8. Evaluate adaptive re-ranking\n",
        "9. Generate threshold analysis plots\n",
        "10. Serialize results to MATLAB\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive (optional - if you want to save results)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!git clone --recursive https://github.com/FarInHeight/Visual-Place-Recognition-Project.git\n",
        "%cd Visual-Place-Recognition-Project\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install image matching models\n",
        "%cd image-matching-models\n",
        "!pip install -e .[all]\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install other dependencies\n",
        "!pip install faiss-cpu scikit-learn joblib matplotlib scipy tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Download Datasets\n",
        "\n",
        "**Note**: You may need to download datasets manually from Google Drive links and upload them to Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download datasets (if not already downloaded)\n",
        "# Note: You may need to download manually from Google Drive links\n",
        "# !python download_datasets.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Run VPR Evaluation\n",
        "\n",
        "Run this for each test dataset (SF-XS, Tokyo-XS, SVOX)\n",
        "\n",
        "**Important**: Replace `[timestamp]` with the actual timestamp from your log directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: SF-XS Test\n",
        "# Replace paths with your actual dataset paths\n",
        "!python VPR-methods-evaluation/main.py \\\n",
        "  --num_workers 4 \\\n",
        "  --batch_size 32 \\\n",
        "  --log_dir log_sf_xs_test \\\n",
        "  --method=cosplace --backbone=ResNet18 --descriptors_dimension=512 \\\n",
        "  --image_size 512 512 \\\n",
        "  --database_folder data/sf_xs/test/database \\\n",
        "  --queries_folder data/sf_xs/test/queries \\\n",
        "  --num_preds_to_save 20 \\\n",
        "  --recall_values 1 5 10 20 \\\n",
        "  --save_for_uncertainty \\\n",
        "  --device cuda\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Extract Features (8 Improved Features)\n",
        "\n",
        "**Important**: Replace `[timestamp]` with the actual timestamp from your log directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract features for test (SF-XS test)\n",
        "# Replace [timestamp] with actual timestamp\n",
        "!python -m extension_6_1.stage_1_extract_features_no_inliers \\\n",
        "  --preds-dir logs/log_sf_xs_test/[timestamp]/preds \\\n",
        "  --z-data-path logs/log_sf_xs_test/[timestamp]/z_data.torch \\\n",
        "  --output-path data/features_and_predictions/features_sf_xs_test_improved.npz \\\n",
        "  --positive-dist-threshold 25\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Train Logistic Regression Model\n",
        "\n",
        "**Note**: You need training and validation features first (SVOX train, SF-XS val).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train model with C tuning\n",
        "!python -m extension_6_1.stage_3_train_logreg_easy_queries \\\n",
        "  --train-features data/features_and_predictions/features_svox_train_improved.npz \\\n",
        "  --val-features data/features_and_predictions/features_sf_xs_val_improved.npz \\\n",
        "  --output-model logreg_easy_queries_optimal_C_tuned.pkl \\\n",
        "  --threshold-method f1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Apply Model with Threshold Calibration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply to SF-XS test (with calibration)\n",
        "!python -m extension_6_1.stage_4_apply_logreg_easy_queries \\\n",
        "  --model-path logreg_easy_queries_optimal_C_tuned.pkl \\\n",
        "  --feature-path data/features_and_predictions/features_sf_xs_test_improved.npz \\\n",
        "  --output-path data/features_and_predictions/logreg_sf_xs_test.npz \\\n",
        "  --hard-queries-output data/features_and_predictions/hard_queries_sf_xs_test.txt \\\n",
        "  --calibrate-threshold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Run Full Re-ranking (Ground Truth)\n",
        "\n",
        "**Important**: Run full re-ranking FIRST to get ground-truth results. This is the longest step (~2-4 hours).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run full re-ranking for SF-XS test (all queries)\n",
        "# Replace [timestamp] with actual timestamp\n",
        "!python match_queries_preds.py \\\n",
        "  --preds-dir logs/log_sf_xs_test/[timestamp]/preds \\\n",
        "  --matcher superpoint-lg \\\n",
        "  --device cuda \\\n",
        "  --num-preds 20 \\\n",
        "  --out-dir logs/log_sf_xs_test/[timestamp]/preds_superpoint-lg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Run Adaptive Image Matching (Only Hard Queries)\n",
        "\n",
        "This is much faster than full re-ranking since it only processes hard queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run adaptive matching (only hard queries)\n",
        "# Replace [timestamp] with actual timestamp\n",
        "!python match_queries_preds_adaptive.py \\\n",
        "  --preds-dir logs/log_sf_xs_test/[timestamp]/preds \\\n",
        "  --hard-queries-list data/features_and_predictions/hard_queries_sf_xs_test.txt \\\n",
        "  --out-dir logs/log_sf_xs_test/[timestamp]/preds_superpoint-lg_adaptive \\\n",
        "  --matcher superpoint-lg \\\n",
        "  --device cuda \\\n",
        "  --num-preds 20\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Evaluate Adaptive Re-ranking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate adaptive re-ranking\n",
        "# Replace [timestamp] with actual timestamp\n",
        "!python -m extension_6_1.stage_5_adaptive_reranking_eval \\\n",
        "  --preds-dir logs/log_sf_xs_test/[timestamp]/preds \\\n",
        "  --inliers-dir logs/log_sf_xs_test/[timestamp]/preds_superpoint-lg_adaptive \\\n",
        "  --logreg-output data/features_and_predictions/logreg_sf_xs_test.npz \\\n",
        "  --num-preds 20 \\\n",
        "  --positive-dist-threshold 25 \\\n",
        "  --recall-values 1 5 10 20\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Threshold Analysis (Generate Plots)\n",
        "\n",
        "This generates plots showing R@1 vs threshold with selected threshold markers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run comprehensive threshold analysis\n",
        "# Replace [timestamp] with actual timestamps\n",
        "!python adaptive_reranking_threshold_analysis.py \\\n",
        "  --model-path logreg_easy_queries_optimal_C_tuned.pkl \\\n",
        "  --datasets sf_xs_test tokyo_xs_test \\\n",
        "  --feature-paths \\\n",
        "    data/features_and_predictions/features_sf_xs_test_improved.npz \\\n",
        "    data/features_and_predictions/features_tokyo_xs_test_improved.npz \\\n",
        "  --preds-dirs \\\n",
        "    logs/log_sf_xs_test/[timestamp]/preds \\\n",
        "    log_tokyo_xs_test/[timestamp]/preds \\\n",
        "  --inliers-dirs \\\n",
        "    logs/log_sf_xs_test/[timestamp]/preds_superpoint-lg \\\n",
        "    log_tokyo_xs_test/[timestamp]/preds_superpoint-lg \\\n",
        "  --output-dir output_stages/threshold_analysis_comprehensive \\\n",
        "  --threshold-range 0.1 0.99 \\\n",
        "  --threshold-step 0.05 \\\n",
        "  --num-preds 20 \\\n",
        "  --positive-dist-threshold 25\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Serialize Results to MATLAB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Serialize results to MATLAB .mat files\n",
        "!python serialize_results_to_matlab.py \\\n",
        "  --results-dir output_stages/threshold_analysis_comprehensive \\\n",
        "  --model-path logreg_easy_queries_optimal_C_tuned.pkl \\\n",
        "  --feature-path data/features_and_predictions/features_sf_xs_test_improved.npz \\\n",
        "  --output-dir output_stages/matlab_files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Download Results\n",
        "\n",
        "Download plots and results before the Colab session ends.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download plots and results\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Create zip file with results\n",
        "with zipfile.ZipFile('results.zip', 'w') as zipf:\n",
        "    # Add plots\n",
        "    if os.path.exists('output_stages/threshold_analysis_comprehensive'):\n",
        "        for file in os.listdir('output_stages/threshold_analysis_comprehensive'):\n",
        "            if file.endswith('.png'):\n",
        "                zipf.write(f'output_stages/threshold_analysis_comprehensive/{file}')\n",
        "        # Add summary reports\n",
        "        for file in os.listdir('output_stages/threshold_analysis_comprehensive'):\n",
        "            if file.endswith('.md'):\n",
        "                zipf.write(f'output_stages/threshold_analysis_comprehensive/{file}')\n",
        "    \n",
        "    # Add MATLAB files\n",
        "    if os.path.exists('output_stages/matlab_files'):\n",
        "        for file in os.listdir('output_stages/matlab_files'):\n",
        "            if file.endswith('.mat'):\n",
        "                zipf.write(f'output_stages/matlab_files/{file}')\n",
        "\n",
        "# Download\n",
        "files.download('results.zip')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Important Notes\n",
        "\n",
        "### ‚ùì Do You Need Colab Pro?\n",
        "\n",
        "**Answer: NO! Free Colab works fine for most steps.**\n",
        "\n",
        "| Step | Free Colab? | Notes |\n",
        "|------|-------------|-------|\n",
        "| VPR Evaluation | ‚úÖ Yes | Fast (~5-10 min), no timeout risk |\n",
        "| Feature Extraction | ‚úÖ Yes | Very fast (~1-2 min) |\n",
        "| Model Training | ‚úÖ Yes | Fast (~1-2 min) |\n",
        "| Model Application | ‚úÖ Yes | Very fast (~1 min) |\n",
        "| **Full Re-ranking** | ‚ö†Ô∏è **Maybe** | **2-4 hours - may timeout on free tier** |\n",
        "| Adaptive Matching | ‚úÖ Yes | 30-60 min, usually fine |\n",
        "| Threshold Analysis | ‚úÖ Yes | Fast (~10-20 min) |\n",
        "\n",
        "### Free Colab Limitations:\n",
        "1. **Session timeout**: ~12 hours of inactivity (keep tab active!)\n",
        "2. **GPU hours**: ~12 hours/day (usually enough)\n",
        "3. **Storage**: ~80GB (usually enough)\n",
        "4. **File persistence**: Files deleted when session ends (save to Drive!)\n",
        "\n",
        "### Recommendations for Free Colab:\n",
        "1. **Save to Google Drive**: Mount Drive and save important results\n",
        "2. **Use GPU**: Enable GPU in Runtime ‚Üí Change runtime type (T4 is free!)\n",
        "3. **Keep tab active**: During long operations to prevent timeout\n",
        "4. **Hybrid approach**: Run full re-ranking locally if you have GPU\n",
        "5. **Download results**: Download plots and .mat files before session ends\n",
        "\n",
        "### When You Might Need Colab Pro:\n",
        "- ‚ùå You don't have a local GPU AND need to run full re-ranking in Colab\n",
        "- ‚ùå You need background execution (can't keep tab active)\n",
        "- ‚ùå You need more than 12 GPU hours/day\n",
        "- ‚ùå You need 24-hour sessions (vs 12 hours on free)\n",
        "\n",
        "### Time Estimates (Free Colab with T4 GPU):\n",
        "- VPR evaluation: ~5-10 minutes per dataset ‚úÖ\n",
        "- Full re-ranking: ~2-4 hours per dataset ‚ö†Ô∏è (may timeout)\n",
        "- Adaptive matching: ~30-60 minutes ‚úÖ\n",
        "- Threshold analysis: ~10-20 minutes ‚úÖ\n",
        "\n",
        "### Best Strategy for Free Colab:\n",
        "1. **Colab (Free)**: VPR evaluation, feature extraction, model training/application\n",
        "2. **Local (if GPU)**: Full re-ranking (no timeout risk)\n",
        "3. **Colab (Free)**: Adaptive matching, threshold analysis\n",
        "4. **Download**: All results before session ends\n",
        "\n",
        "**This way, you don't need Colab Pro!** üéâ\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
